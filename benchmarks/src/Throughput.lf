/**
 * Micro-benchmark from the Savina benchmark suite, where it is called Fork Join.
 * See https://shamsimam.github.io/papers/2014-agere-savina.pdf.
 *
 * According to the Savina paper performance can be achieved by
 * batch processing messages in the worker actors.
 * This is not possible with reactors because scheduling and
 * advancing logical time occurs after each round of
 * message delivery.
 */
target C {
    files: ["../lib/benchmark_runner.h"],
    timeout: 300 msec, // The last 2 nsec is for the runner summary.
    workers: 1,
};

import BenchmarkRunner from "../lib/BenchmarkRunner.lf";

preamble {=
    #include "benchmark_runner.h"
=}

reactor ThroughputReactor(totalMessages:size_t=10000) {

    preamble {=
        #include <math.h>

        void performComputation(double theta) {
            double sint = sin(theta);
            // volatile to defeat dead code elimination
            volatile double res = sint * sint;
        }
    =}

    input inMessage:bool;
    state count:int = 0;

    @wcet("50 usec")
    reaction(inMessage) {=
        performComputation(37.2);

        self->count++;
        if (self->count == self->totalMessages) {
            lf_print("Success: performed computation %d times", self->count);
            self->count = 0;
        }
    =}
}

realtime reactor ThroughputProducer(totalMessages:size_t=10000, numConsumer:size_t=60) {
    state sent_messages: size_t=0;
    input start:bool;
    output finished:bool;

    output outMessage_0:bool;
    output outMessage_1:bool;
    output outMessage_2:bool;

    // replaced by following two ports logical action send_next_msg;
    input send_next_msg_input: int;
    output send_next_msg_output: int;

    @wcet("5 usec")
    reaction(start, send_next_msg_input) -> send_next_msg_output, finished, outMessage_0, outMessage_1, outMessage_2 {=
        lf_set_present(outMessage_0);
        lf_set_present(outMessage_1);
        lf_set_present(outMessage_2);
        
        self->sent_messages++;
        if (self->sent_messages == self->totalMessages) {
            // reset state
            self->sent_messages = 0;
            lf_set_present(finished);
        } else {
            lf_set_present(send_next_msg_output);
        }
    =}
}

main reactor (numIterations:size_t=12, numMessagesPerReactor:size_t=100, numWorkers:size_t=60)
{
    runner = new BenchmarkRunner(num_iterations=numIterations);
    runner.doneOut -> runner.doneIn after 3 msec;
    runner.nextIterationOut -> runner.nextIterationIn after 15 msec; // try 10 msec

    producer = new ThroughputProducer(totalMessages=numMessagesPerReactor, numConsumer=numWorkers);

    producer.send_next_msg_output -> producer.send_next_msg_input after 3 msec;
   
    runner.start -> producer.start;

    producer.finished -> runner.finish;

    // Manually instantiate a bank
    worker_0 = new ThroughputReactor(totalMessages=numMessagesPerReactor);
    producer.outMessage_0 -> worker_0.inMessage
    worker_1 = new ThroughputReactor(totalMessages=numMessagesPerReactor);
    producer.outMessage_1 -> worker_1.inMessage
    worker_2 = new ThroughputReactor(totalMessages=numMessagesPerReactor);
    producer.outMessage_2 -> worker_2.inMessage
}
